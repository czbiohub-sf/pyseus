{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook to run through OpenCell mass-spec processing.\n",
    "The full OC mass-spec results file resides in the CZBMPI_interactome in Google Drive. \n",
    "Our final processing was used from \"Pulldown_Results_4x11Plates\", which used MBR from 11 plates. \n",
    "Here, the example is using 3 plates. \n",
    "\n",
    "Usually, sample names have to be edited to fit the proper format for the scripts, refer to \"change_sample_names.ipynb\" for a guide to changing sample names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "from pyseus import basic_processing as ip\n",
    "from pyseus import primary_analysis as pa\n",
    "from pyseus import validation_analysis as va\n",
    "from pyseus import stoichiometry as stoi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign parameters\n",
    "Imputation:\n",
    "For small batches, bait imputation performs better to fill out missing values. \n",
    "For large batches, there usually is no need for imputation except for some proteingroups that may not have enough sample size. In such case we use prey imputation where we impute around the mean intensity of the proteingroup. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data/OC_Plate_22-25_MBR/'\n",
    "analysis = '20220726'\n",
    "\n",
    "# this is a renamed pg file from 'change_sample_names.ipynb'\n",
    "pg_file = 'proteinGroups_renamed.txt'\n",
    "\n",
    "# Use LFQ or absolute intensity\n",
    "intensity_type = 'LFQ intensity'\n",
    "\n",
    "# Imputation parameters\n",
    "impute_mode = 'bait' # another mode is 'prey', if you do not wish to impute, set it to 'prey' with a very high threshold\n",
    "\n",
    "distance = 1.8\n",
    "width = 0.3\n",
    "\n",
    "thresh=100 # For prey-imputation, number of samples needed to skip imputation in a row\n",
    "\n",
    "# regular expression to group the replicates together\n",
    "regexp = r'(P\\d{3})(?:.\\d{2})?(_.*)_\\d{2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Processing\n",
    "The standard processing goes through multiple steps: MQ filtering, log2 transformation, grouping triplicates, removing invalid rows, imputation, and creating bait matrix. Please refer to pyseus ReadTheDocs for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 169 of 3829 rows. Now 3660 rows.\n",
      "Removed invalid rows. 3448 from 3660 rows remaining.\n"
     ]
    }
   ],
   "source": [
    "initial_tables = ip.opencell_initial_processing(\n",
    "    root=root,\n",
    "    analysis=analysis,\n",
    "    pg_file=pg_file,\n",
    "    intensity_type=intensity_type,\n",
    "    impute=impute_mode,\n",
    "    distance=distance,\n",
    "    width=width,\n",
    "    thresh=thresh,\n",
    "    group_regexp=regexp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are saving the intermediary tables to the designated analysis folder\n",
    "initial_tables.bait_imputed_table.to_csv(root + analysis + '/imputed_table.csv')\n",
    "initial_tables.bait_matrix.to_csv(root + analysis + '/analysis_exclusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate p-values and Enrichment\n",
    "For p-val calculation, we use the AnalysisTables class in primary_analysis.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate class for calculating p-val and enrichment\n",
    "an_tables = pa.AnalysisTables(\n",
    "    root=root,\n",
    "    analysis=analysis,\n",
    "    grouped_table=initial_tables.bait_imputed_table,\n",
    "    exclusion_matrix = initial_tables.bait_matrix)\n",
    "\n",
    "an_tables.load_exclusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P022_ATL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P022_CDKN2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P022_CLTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P022_COMMD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P022_COMMD2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>P025_YWHAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>P025_YWHAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>P025_YWHAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>P025_YWHAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>P025_YWHAZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Samples\n",
       "1      P022_ATL3\n",
       "2    P022_CDKN2A\n",
       "3      P022_CLTA\n",
       "4    P022_COMMD1\n",
       "5    P022_COMMD2\n",
       "..           ...\n",
       "118   P025_YWHAE\n",
       "119   P025_YWHAG\n",
       "120   P025_YWHAH\n",
       "121   P025_YWHAQ\n",
       "122   P025_YWHAZ\n",
       "\n",
       "[122 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Self explanatory Methods\n",
    "\n",
    "# an_tables.print_baits()\n",
    "# an_tables.print_excluded_controls('Glycine_Low_pH_LAMP1')\n",
    "an_tables.print_controls('P022_AAMP')\n",
    "# an_tables.select_wildtype_controls(wt_re='_WT')\n",
    "# an_tables.restore_default_exclusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below shows two options, simple pval calculation or two-step bootstrap calculation. For clarification of the difference in two methods, please refer to the readthedocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-val calculations..\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Simple Calculation\n",
    "# calculate p-val ane enrichment, and convert table to standard format for validation\n",
    "an_tables.simple_pval_enrichment(std_enrich=False)\n",
    "an_tables.convert_to_standard_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First round p-val calculations..\n",
      "First round finished!\n",
      "Second round p-val calculations...\n",
      "Second round finished!\n"
     ]
    }
   ],
   "source": [
    "# Two step bootstrap pval calculation\n",
    "an_tables.two_step_bootstrap_pval_enrichment(std_enrich=True)\n",
    "an_tables.convert_to_standard_table(simple_analysis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pval/enrichment table\n",
    "an_tables.standard_hits_table.to_csv(root + analysis + '/standard_pval_table.csv')\n",
    "\n",
    "# save the wide table\n",
    "an_tables.simple_pval_table.to_csv(root + analysis + '/wide_pval_table.csv')\n",
    "# an_tables.two_step_pval_table.to_csv(root + analysis + '/wide_pval_table.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we call FDR for interaction calling. Here we are using dynamic FDR as described by the paper. \n",
    "For this we use Validation class from validation_analyses.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate class\n",
    "vali = va.Validation(hit_table = an_tables.standard_hits_table, target_col='target', prey_col='prey')\n",
    "\n",
    "# perc is the parameter that determines how strict the interaction calling.  \n",
    "vali.dynamic_fdr(perc=10)\n",
    "\n",
    "# save the full table and just the interaction table\n",
    "vali.called_table.to_csv(root + analysis + '/full_hits_table.csv')\n",
    "vali.interaction_table.to_csv(root + analysis + '/interactions_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stoichiometry calculations\n",
    "\n",
    "To do so, we need the imputed table from basic processing, and the wide pval-table from analysis, along with some other required files.\n",
    "These are found in the stoichiometry_input directory\n",
    "\n",
    "The script for stoichiometry calculation is found in stoichiometry.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary input files\n",
    "# read the accompanying Confluence page for details on how to retrieve/generate these files\n",
    "\n",
    "pulldown_meta = pd.read_csv('../data/stoichiometry_input/pulldown_metadata_1002.csv')\n",
    "total_abundances = pd.read_csv('../data/stoichiometry_input/HEK_abundance_digitonin_rnaseq_ensg.csv')\n",
    "seq_table = stoi.fasta_df('../data/stoichiometry_input/uniprot_proteome.fasta')\n",
    "ensembl_uniprot = pd.read_csv('../data/stoichiometry_input/ensembl_uniprot_association.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kibeom.kim/opt/anaconda3/envs/pyseus/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/kibeom.kim/opt/anaconda3/envs/pyseus/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# For 'pvals', here we use wide-pval table from analysis - an_tables.simple_pval_table, \n",
    "# but it could be an_tables.two_step_pval_table if you used two-step bootstrapping\n",
    "\n",
    "stois, pg_mapping = stoi.compute_stoich_df(imputed=initial_tables.bait_imputed_table,\n",
    "    seq_df=seq_table, rnaseq=total_abundances, pvals=an_tables.simple_pval_table,\n",
    "    pull_uni=pulldown_meta, ensembl_uniprot=ensembl_uniprot,\n",
    "    target_re=r'P(\\d{3}_.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the stoichiometry table, pg_mapping is a pg<->ensg mapping that may be useful as a reference\n",
    "stois.to_csv(root + analysis + '/stoichiometry_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('pyseus_minimum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "4f9eaa72b302f95492a7962f765d4c258b54a123165a740f4464c5d6cbafb102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
